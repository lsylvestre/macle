Soit un tableau [a] de 1000 éléments, tous valant 10.

On calcule la somme des fib(i) pour chaque élément i du tableau.

Avec la version [array_fold_left] classique,
le calcul prend 391 us.

Avec la version [reduce-by 1],
le calcul prend 474 us (ce qui suggère que le passage par un tableau VHDL (de taille 1)
engendre un surcoût.

Avec la version [reduce-by 10],
le calcul prend 140 us.
Cela confirme que le reduce-by est plus efficace,
et surtout que l'on profite du parallélisme (ici fois 10 => gain de 2,8).

Par la suite, on a 
[reduce-by 20] ~> 120 us.
[reduce-by 50] ~> 108 us.
[reduce-by 100] ~> 104 us (gain de 3,8).

Comme la fonction de réduction retourne en moins de 10 cycles, 
le gain est relativement faible (3,8 pour des paquets de tailles 100).
Puisque, même en mode "burst", la lecture du tableau entier se fait séquentiellement.


-------------------------------------------------

On repète l'expérience avec un tableau [a] de 1000 éléments, tous valant 100.


Avec la version [array_fold_left] classique,
le calcul prend 2191 us.

Avec la version [reduce-by 1],
le calcul prend 2276 us. Le sûrcout devient relativement négligeable.


Avec la version [reduce-by 10],
le calcul prend 322 us.
On profite du parallélisme (ici fois 10 => gain de 6,8).


[reduce-by 20] ~> 211 us (gain de 10,3).
[reduce-by 50] ~> 144 us (gain de 15).
[reduce-by 100] ~> 122 us (gain de 18).



-------------------------------------------------

On repète l'expérience avec un tableau [a] de 1000 éléments, tous valant 1000.


Avec la version [array_fold_left] classique,
le calcul prend 20192 us.


[reduce-by 10] ~> 2120 us (gain de 9,5).
[reduce-by 20] ~> 1110 us (gain de 18).
[reduce-by 50] ~> 504 us (gain de 40).
[reduce-by 100] ~> 302 us (gain de 67).